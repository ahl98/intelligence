#: #############################################################################
#: primary:
#: - name: "<full-lecture-title>"
#:   file: "<url-for-website>" # looks like... /<group>/<semester>/<file>
#:   inst: [<instructor_1>, <instructor_2>, ...]
#:   date: "<MM>/<DD>"
#:   desc: >- # the ">-" specifies to YAML its a multi-line string
#:     <meeting-description>
#: supplementary: ... (same format, just a different key)
#: #############################################################################
primary:
- name: "A Few Useful Things to Know about Machine Learning by Pedro Domingos"
  file: "useful-ml"
  paper: "https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf"
  covr: "https://cdn-images-1.medium.com/max/1600/0*WbHkMBXJILlrXgYj.jpg"
  tags: ["intro", "research", "uwash"]
  inst: ["Waldmannly", "ionlights"]
  desc: >-
    Abstract: Machine learning algorithms can figure out how to perform
    important tasks by generalizing from examples. This is often feasible and
    cost-effective where manual programming is not. As more data becomes
    available, more ambitious problems can be tackled. As a result, machine
    learning is widely used in computer science and other fields. However,
    developing successful machine learning applications requires a substantial
    amount of "black art" that is hard to find in textbooks. This article
    summarizes twelve key lessons that machine learning researchers and
    practitioners have learned. These include pitfalls to avoid, important
    issues to focus on, and answers to common questions.

- name: "Intro to Machine Learning Topics"
  file: "intro-to-ml-topics"
  paper: "https://www.intechopen.com/books/new-advances-in-machine-learning/introduction-to-machine-learning"
  covr: "https://cdn-images-1.medium.com/max/1600/0*WbHkMBXJILlrXgYj.jpg"
  tags: ["intro", "research", "topics", "summary"]
  inst: ["Waldmannly", "ionlights"]
  desc: >-
    Summary: This paper includes a brief introduction to and history of machine
    learning as well as breif summaries of topics in the field.

- name: "Deep Learning"
  file: "deep-learning"
  paper: "https://www.nature.com/articles/nature14539"
  covr: "https://cdn-images-1.medium.com/max/1600/0*WbHkMBXJILlrXgYj.jpg"
  tags: ["intro", "research", "deep-learning", "summary"]
  inst: ["Waldmannly", "ionlights"]
  desc: >-
    Abstract: Deep learning allows for computational models that are composed of
    multiple processing layers to learn representations of data with multiple
    levels of abstraction. These methods have dramatically improved the state-
    of-the-art in speech recognition, visual object recognition, object
    detection and many other domains such as drug discovery and genomics. Deep
    learning discovers intricate structure in large data sets by using the
    backpropagation algorithm to indicate how a machine should change its
    internal parameters that are used to compute the representation in each
    layer from the representation in the previous layer. Deep convolutional
    nets have brought about breakthroughs in processing images, video, speech
    and audio, whereas recurrent nets have shone light on sequential data such
    as text and speech.

- name: "Handwritten Digit Recognition with a Back-Propagation Network"
  file: "first-cnns-backprop"
  paper: "http://yann.lecun.com/exdb/publis/pdf/lecun-90c.pdf"
  covr: "https://www.topbots.com/wp-content/uploads/2017/03/convnet_design_patterns_1600x700_web-1280x640.jpg"
  tags: ["intro", "research", "deep-learning", "conv-nets"]
  inst: ["Waldmannly", "ionlights"]
  desc: >-
    Abstract: We present an application of back-propagation networks to
    hand-written digit recognition. Minimal preprocessing of the data was
    required, but architecture of the network was highly constrained and
    specifically designed for the task. The input of the network consists of
    nromalized images of isolated digits. The method has 1% error rate and
    about a 9% reject rate on zipcode digits provided by the US Postal Service.

- name: "CS294A Lecture notes: Sparse autoencoder"
  file: "sparse-autoencoder"
  paper: "https://web.stanford.edu/class/cs294a/sparseAutoencoder.pdf"
  covr: "https://www.topbots.com/wp-content/uploads/2017/03/convnet_design_patterns_1600x700_web-1280x640.jpg"
  tags: ["intro", "research", "learning", "sparese", "autoencoder", "review", "notes"]
  inst: ["Waldmannly", "ionlights"]
  desc: >-
    Summary: These notes describe the sparse autoencoder learning algorithm, which
    is one approach to automatically learn features from unlabeled data. In some
    domains, such as computer vision, this approach is not by itself competitive
    with the best hand-engineered features, but the features it can learn do turn
    out to be useful for a range of problems (including ones in audio, text, etc).

- name: "A Critical Review of Recurrent Neural Networks for Sequence Learning"
  file: "review-rnn-sequence-learning"
  paper: "https://arxiv.org/pdf/1506.00019.pdf"
  covr: "https://www.topbots.com/wp-content/uploads/2017/03/convnet_design_patterns_1600x700_web-1280x640.jpg"
  tags: ["review", "research", "learning", "sequence", "rnn", "paper"]
  inst: ["Waldmannly", "ionlights"]
  desc: >-
    Summary: Countless learning tasks require dealing with sequential data. Image
    captioning, speech synthesis, and music generation all require that a model 
    produce outputs that are sequences. In other domains, such as time series
    prediction, video analysis, and musical information retrieval, a model must
    learn from inputs that are sequences. Interactive tasks, such as translating
    natural language, engaging in dialogue, and controlling a robot, often demand
    both capabilities. Recurrent neural networks (RNNs) are connectionist models
    that capture the dynamics of sequences via cycles in the network of nodes.
    Unlike standard feedforward neural networks, recurrent networks retain a state
    that can represent information from an arbitrarily long context window. 
    Although recurrent neural networks have traditionally been difficult to train,
    and often contain millions of parameters, recent advances in network
    architectures, optimization techniques, and parallel computation have enabled
    successful large-scale learning with them. In recent years, systems based on
    long short-term memory (LSTM) and bidirectional (BRNN) architectures have
    demonstrated ground-breaking performance on tasks as varied as image
    captioning, language translation, and handwriting recognition. In this survey,
    we review and synthesize the research that over the past three decades first
    yielded and then made practical these powerful learning models. When 
    appropriate, we reconcile conflicting notation and nomenclature. Our goal is
    to provide a selfcontained explication of the state of the art together with
    a historical perspective and references to primary research.

- name: "Deep Visual-Semantic Alignments for Generating Image Descriptions"
  file: "image-description-generation"
  paper: "https://arxiv.org/pdf/1412.2306.pdf"
  covr: "https://www.topbots.com/wp-content/uploads/2017/03/convnet_design_patterns_1600x700_web-1280x640.jpg"
  tags: ["cnn", "captioning", "images", "stanford"]
  inst: ["Waldmannly", "ionlights"]
  desc: >-
    Abstract: We present a model that generates natural language descriptions of
    images and their regions. Our approach leverages datasets of images and their
    sentence descriptions tolearn about the inter-modal correspondences between 
    language and visual data. Our alignment model is based on a novel combination
    of Convolutional Neural Networks over image regions, bidirectional Recurrent
    Neural Networks over sentences, and a structured objective that aligns the 
    two modalities through a multimodal embedding. We then describe a Multimodal
    Recurrent Neural Network architecture that uses the inferred alignments to
    learn to generate novel descriptions of image regions.  We demonstrate that 
    our alignment model produces state of the art results in retrieval experiments
    on Flickr8K, Flickr30K and MSCOCOdatasets. We then show that the generated
    descriptions sig outperform retrieval baselines on both full images and on a
    new dataset of region-level annotations.
